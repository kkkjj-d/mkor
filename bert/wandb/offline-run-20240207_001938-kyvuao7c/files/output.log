+++++++++++++++++++++++++
load!
  0%|                                                                                                           | 0/105316 [00:00<?, ?it/s]/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
  2%|██                                                                                           | 2301/105316 [37:22<24:59:51,  1.14it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc38d6a61f0>
Traceback (most recent call last):
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1328, in __del__
    self._shutdown_workers()
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1301, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
  2%|██                                                                                           | 2301/105316 [37:23<27:53:41,  1.03it/s]
Traceback (most recent call last):
  File "run_pretraining.py", line 739, in <module>
    global_steps, train_time = main(args)
  File "run_pretraining.py", line 650, in main
    take_optimizer_step(optimizer, preconditioner,
  File "run_pretraining.py", line 522, in take_optimizer_step
    scaler.step(optimizer)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 338, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 285, in _maybe_opt_step
    retval = optimizer.step(*args, **kwargs)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/yanxindong/anaconda/envs/eva/lib/python3.8/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/yanxindong/mkor/bert/optimizers/lamb.py", line 109, in step
    weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)
KeyboardInterrupt